{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_anthropic import AnthropicLLM\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "load_dotenv()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "anthropic_api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "langchain_api_key=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "nvidia_api_key=os.getenv(\"NVIDIA_API_KEY\")\n",
    "\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = langchain_api_key\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    api_key=groq_api_key,\n",
    ")\n",
    "\n",
    "loader=PyPDFLoader(\"data.pdf\")\n",
    "docs=loader.load()\n",
    "docs\n",
    "\n",
    "\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "texts = [doc.page_content for doc in docs]\n",
    "txt=[]\n",
    "for i in texts[:10]:\n",
    "    text=text_splitter.split_text(i);\n",
    "    txt.extend(text)\n",
    "\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vectordb = FAISS.from_texts(txt, embedder)\n",
    "\n",
    "\n",
    "retriever=vectordb.as_retriever(search_kwargs={\"k\":3})\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"human\",\"Answer the following Question based on the following {context} Question:{input}\")\n",
    "    \n",
    "])\n",
    "doc_chain = create_stuff_documents_chain(llm, prompt)\n",
    "qa_chain = create_retrieval_chain(retriever, doc_chain)\n",
    "\n",
    "result = qa_chain.invoke({\"input\": \"What does source explains about?\"})\n",
    "print(result[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, the Open Source Driven feature explains that the Data Portal is developed completely using an Open Source Stack. This means that:\n",
      "\n",
      "1. Software costs are saved, as no licenses are required.\n",
      "2. There is provision for community participation in further developing the product, specifically in areas such as:\n",
      "   * Data visualization\n",
      "   * Data consumption\n",
      "   * APIs to access datasets\n",
      "\n",
      "This suggests that the Data Portal is an open and collaborative platform that encourages community involvement and contribution to its development, with the goal of making it a more robust and useful tool for data management and analysis.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
